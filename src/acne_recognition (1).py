# -*- coding: utf-8 -*-
"""Acne Recognition.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19LqWinmp98QfJfqcUd4LrlIyrL3JYyWF

## Importing Libraries
"""

pip install opendatasets

import opendatasets as od

od.download("https://www.kaggle.com/datasets/rutviklathiyateksun/acne-grading-classificationdataset/data")

import os
import cv2
import random
import numpy as np
import matplotlib.pyplot as plt
from tqdm import tqdm
import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, RandomFlip, RandomRotation, RandomZoom, RandomBrightness, RandomContrast, RandomTranslation

from tensorflow.keras.applications import EfficientNetB0
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.preprocessing import image

"""### Renaming Target Class Variables"""

os.rename("/content/acne-grading-classificationdataset/Created Dataset/Level_0", "/content/acne-grading-classificationdataset/Created Dataset/Mild")
os.rename("/content/acne-grading-classificationdataset/Created Dataset/Level_1", "/content/acne-grading-classificationdataset/Created Dataset/Medium")
os.rename("/content/acne-grading-classificationdataset/Created Dataset/Level_2", "/content/acne-grading-classificationdataset/Created Dataset/Severe")

"""### Displaing Sample Images"""

path = "/content/acne-grading-classificationdataset/Created Dataset"
count = 1
classes = os.listdir(path)

plt.figure(figsize=(12, 8))

for i, j in enumerate(classes):
    class_path = os.path.join(path, j)
    images = os.listdir(class_path)
    sample_images = random.sample(images, min(4, len(images)))

    for img_name in sample_images:
        img_path = os.path.join(class_path, img_name)
        img = cv2.imread(img_path)
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        plt.subplot(len(classes), 4, count)
        plt.imshow(img)
        plt.axis("off")
        plt.title(j)
        count += 1

plt.tight_layout()
plt.show()

"""### Removing Background"""

def remove_black(img):
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    mask = gray > 10
    coords = np.argwhere(mask)
    if coords.size == 0:
        return img
    y0, x0 = coords.min(axis=0)
    y1, x1 = coords.max(axis=0)
    cropped = img[y0:y1, x0:x1]
    gray_crop = cv2.cvtColor(cropped, cv2.COLOR_BGR2GRAY)
    mask_white = gray_crop <= 10
    cropped[mask_white] = [255, 255, 255]
    return cropped

input_root = "/content/acne-grading-classificationdataset/Created Dataset"
output_root = "/content/acne-grading-classificationdataset/Processed"
os.makedirs(output_root, exist_ok=True)

for class_name in os.listdir(input_root):
    class_path = os.path.join(input_root, class_name)
    output_class = os.path.join(output_root, class_name)
    os.makedirs(output_class, exist_ok=True)

    for fname in tqdm(os.listdir(class_path), desc=f"Processing {class_name}"):
        if not fname.lower().endswith((".jpg", ".jpeg", ".png")):
            continue
        img = cv2.imread(os.path.join(class_path, fname))
        if img is None:
            continue
        processed = remove_black(img)
        cv2.imwrite(os.path.join(output_class, fname), processed)

"""### Displaying Processed Images"""

path = "/content/acne-grading-classificationdataset/Processed"
count = 1
classes = os.listdir(path)

plt.figure(figsize=(12, 8))

for i, j in enumerate(classes):
    class_path = os.path.join(path, j)
    images = os.listdir(class_path)
    sample_images = random.sample(images, min(4, len(images)))

    for img_name in sample_images:
        img_path = os.path.join(class_path, img_name)
        img = cv2.imread(img_path)
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        plt.subplot(len(classes), 4, count)
        plt.imshow(img)
        plt.axis("off")
        plt.title(j)
        count += 1

plt.tight_layout()
plt.show()

"""### Augmenting Images to 30k"""

data_augmentation_layer = Sequential([
    RandomFlip("horizontal_and_vertical"),
    RandomRotation(0.2),
    RandomZoom(0.2),
    RandomBrightness(0.2),
    RandomContrast(0.2),
    RandomTranslation(0.1, 0.1)
])

def augment_image_with_layer(img):
    img_tensor = tf.convert_to_tensor(img, dtype=tf.float32)
    augmented_img_tensor = data_augmentation_layer(tf.expand_dims(img_tensor, 0), training=True)
    return tf.squeeze(augmented_img_tensor, 0)


path = "/content/acne-grading-classificationdataset/Processed"
target_image_count = 10000


for class_name in os.listdir(path):
    class_path = os.path.join(path, class_name)
    if not os.path.isdir(class_path):
        continue

    images = [f for f in os.listdir(class_path)
              if f.lower().endswith(('.png', '.jpg', '.jpeg', '.webp'))]
    current_count = len(images)

    if current_count >= target_image_count:
        print(f" {class_name} already has {current_count} images.")
        continue

    needed_count = target_image_count - current_count
    print(f" Augmenting class '{class_name}' | Current: {current_count}, Target: {target_image_count}, Need: {needed_count}")

    for i in tqdm(range(needed_count), desc=f"Augmenting {class_name}"):
        img_name = random.choice(images)
        img_path = os.path.join(class_path, img_name)

        img = cv2.imread(img_path)
        if img is None:
            continue
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

        augmented_img_tensor = augment_image_with_layer(img)
        augmented_img = tf.cast(augmented_img_tensor, dtype=tf.uint8).numpy()
        augmented_img = cv2.cvtColor(augmented_img, cv2.COLOR_RGB2BGR)

        new_img_name = f"augmented_{i}_{img_name}"
        new_img_path = os.path.join(class_path, new_img_name)
        cv2.imwrite(new_img_path, augmented_img)

"""### Loading Train and Validation Testing"""

train_ds = tf.keras.preprocessing.image_dataset_from_directory(
    "/content/drive/MyDrive/acne_project/acne-grading-classificationdataset/Processed",
    validation_split = 0.2,
    subset = "training",
    seed =123,
    image_size = (224, 224),
    batch_size= 32
)

val_ds = tf.keras.preprocessing.image_dataset_from_directory(
    "/content/drive/MyDrive/acne_project/acne-grading-classificationdataset/Processed",
    validation_split = 0.2,
    subset = "validation",
    seed = 123,
    image_size = (224,224),
    batch_size = 32
)

path = "/content/acne-grading-classificationdataset/Processed"

for cls in os.listdir(path):
  folder = os.path.join(path, cls)
  for f in tqdm(os.listdir(folder)):
    img_path = os.path.join(folder, f)
    img = cv2.imread(img_path, cv2.IMREAD_UNCHANGED)
    if img is None:
      print("corrumpt")
      continue
    if img.ndim != 3  or img.shape[-1] != 3:
      print("Not rgb")

"""### Loading Trained Model"""

from tensorflow.keras.models import load_model

model = load_model("/content/model.keras")

model.summary()

last = model.layers[-1]
print("Layer:", last.name)

for i, w in enumerate(last.get_weights()):
    print(f"Weights {i} â†’ shape {w.shape}, mean={np.mean(w):.5f}, std={np.std(w):.5f}")

"""### Calculating on Test Data"""

model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

val_loss, val_acc = model.evaluate(val_ds)
print(f"âœ… Final Validation Accuracy: {val_acc:.3f}")

"""### Testing images form Internet"""

test_dir = "/content/drive/MyDrive/acne_project/Testers"
processed_dir = "/content/drive/MyDrive/acne_project/Processed_testers"
os.makedirs(processed_dir, exist_ok=True)

for fname in os.listdir(test_dir):
    if not fname.lower().endswith(('.jpg', '.jpeg', '.png')):
        continue
    img = cv2.imread(os.path.join(test_dir, fname))
    if img is not None:
        processed = remove_black(img)
        cv2.imwrite(os.path.join(processed_dir, fname), processed)

class_labels = ['Medium', 'Mild', 'Severe']

for filename in os.listdir(processed_dir):
    img = image.load_img(os.path.join(processed_dir, filename), target_size=(224, 224))
    img_array = np.expand_dims(image.img_to_array(img), axis=0)
    preds = model.predict(img_array)
    print(f"{filename}: {class_labels[np.argmax(preds)]}")

pip install streamlit

!pip install streamlit pyngrok opencv-python-headless pillow tensorflow

!npm install -g localtunnel

get_ipython().system_raw('streamlit run app.py &')
!lt --port 8501

streamlit run app.py

# Install dependencies
!pip install tensorflow opencv-python-headless pillow gradio

# -------------------------------
# Imports
# -------------------------------
import gradio as gr
import cv2
import numpy as np
from PIL import Image
import tensorflow as tf
from tensorflow.keras.models import load_model
from tensorflow.keras.applications.efficientnet import preprocess_input

# -------------------------------
# Load model (hardcoded path)
# -------------------------------
model_path = "/content/model.keras"  # adjust if needed
model = load_model(model_path, compile=False)

# -------------------------------
# Preprocessing function to remove black borders
# -------------------------------
def remove_black(img):
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    mask = gray > 10
    coords = np.argwhere(mask)
    if coords.size == 0:
        return img
    y0, x0 = coords.min(axis=0)
    y1, x1 = coords.max(axis=0)
    cropped = img[y0:y1, x0:x1]
    gray_crop = cv2.cvtColor(cropped, cv2.COLOR_BGR2GRAY)
    mask_white = gray_crop <= 10
    cropped[mask_white] = [255, 255, 255]
    return cropped

# -------------------------------
# Preprocess image for the model
# -------------------------------
def preprocess_image(image: np.ndarray, target_size=(224,224)):
    # Apply remove_black first
    img_bgr = cv2.cvtColor(image, cv2.COLOR_RGB2BGR) # Convert to BGR for remove_black
    processed_img_bgr = remove_black(img_bgr)
    processed_img_rgb = cv2.cvtColor(processed_img_bgr, cv2.COLOR_BGR2RGB) # Convert back to RGB

    # Resize and preprocess for the model
    resized_img = cv2.resize(processed_img_rgb, target_size)
    img_float = preprocess_input(resized_img.astype(np.float32))
    return img_float

# -------------------------------
# Prediction function
# -------------------------------
def predict_severity(image):
    img_float = preprocess_image(image)
    img_tensor = np.expand_dims(img_float, axis=0)
    preds = model.predict(img_tensor, verbose=0)
    labels = ['Mild', 'Medium', 'Severe']
    idx = np.argmax(preds[0])
    label = labels[idx]
    confidence = preds[0][idx] * 100
    return f"Predicted Severity: {label} ({confidence:.1f}%)"

# -------------------------------
# Gradio Interface
# -------------------------------
iface = gr.Interface(
    fn=predict_severity,
    inputs=gr.Image(type="numpy"),
    outputs="text",
    title="ðŸ”¬ Acne Severity Classifier",
    description="Upload a facial image to classify acne severity."
)

iface.launch(inline=True)

